{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "step-1-md",
            "metadata": {},
            "source": [
                "# Wide & Deep Model Implementation\n",
                "\n",
                "이 노트북에서는 Google의 **Wide & Deep Learning** 모델을 구현합니다.\n",
                "- **Wide Component**: 암기(Memorization)를 담당. 여기서는 영화의 **장르(Genre)** 정보를 사용합니다.\n",
                "- **Deep Component**: 일반화(Generalization)를 담당. 유저와 아이템의 **임베딩(Embedding)**을 사용합니다.\n",
                "\n",
                "### 1. 데이터 로드 및 전처리"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "step-1-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data size: 3200020\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>userId</th>\n",
                            "      <th>movieId</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>timestamp</th>\n",
                            "      <th>title</th>\n",
                            "      <th>genres</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>10685861</th>\n",
                            "      <td>66954</td>\n",
                            "      <td>781</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>850944577</td>\n",
                            "      <td>Stealing Beauty (1996)</td>\n",
                            "      <td>Drama</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1552723</th>\n",
                            "      <td>9877</td>\n",
                            "      <td>574</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>945495614</td>\n",
                            "      <td>Spanking the Monkey (1994)</td>\n",
                            "      <td>Comedy|Drama</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6145184</th>\n",
                            "      <td>38348</td>\n",
                            "      <td>1088</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>999974867</td>\n",
                            "      <td>Dirty Dancing (1987)</td>\n",
                            "      <td>Drama|Musical|Romance</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16268584</th>\n",
                            "      <td>101952</td>\n",
                            "      <td>2706</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>1203077565</td>\n",
                            "      <td>American Pie (1999)</td>\n",
                            "      <td>Comedy|Romance</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>22418634</th>\n",
                            "      <td>140400</td>\n",
                            "      <td>275079</td>\n",
                            "      <td>3.5</td>\n",
                            "      <td>1653782463</td>\n",
                            "      <td>Chip 'n Dale: Rescue Rangers (2022)</td>\n",
                            "      <td>Adventure|Animation|Children|Comedy|Fantasy|My...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          userId  movieId  rating   timestamp  \\\n",
                            "10685861   66954      781     5.0   850944577   \n",
                            "1552723     9877      574     4.0   945495614   \n",
                            "6145184    38348     1088     2.0   999974867   \n",
                            "16268584  101952     2706     1.0  1203077565   \n",
                            "22418634  140400   275079     3.5  1653782463   \n",
                            "\n",
                            "                                        title  \\\n",
                            "10685861               Stealing Beauty (1996)   \n",
                            "1552723            Spanking the Monkey (1994)   \n",
                            "6145184                  Dirty Dancing (1987)   \n",
                            "16268584                  American Pie (1999)   \n",
                            "22418634  Chip 'n Dale: Rescue Rangers (2022)   \n",
                            "\n",
                            "                                                     genres  \n",
                            "10685861                                              Drama  \n",
                            "1552723                                        Comedy|Drama  \n",
                            "6145184                               Drama|Musical|Romance  \n",
                            "16268584                                     Comedy|Romance  \n",
                            "22418634  Adventure|Animation|Children|Comedy|Fantasy|My...  "
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import MultiLabelBinarizer\n",
                "\n",
                "# 1. 데이터 로드\n",
                "ratings = pd.read_csv('../data/ratings.csv')\n",
                "movies = pd.read_csv('../data/movies.csv')\n",
                "\n",
                "# 2. 데이터 병합 (평점 + 영화 정보)\n",
                "data = pd.merge(ratings, movies, on='movieId')\n",
                "\n",
                "# 3. 데이터 샘플링 (속도를 위해 10%만 사용)\n",
                "data = data.sample(frac=0.1, random_state=42)\n",
                "\n",
                "print(f\"Data size: {len(data)}\")\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step-2-md",
            "metadata": {},
            "source": [
                "### 2. Feature Engineering (Wide & Deep Input)\n",
                "- **Deep Input**: `userId`, `movieId` (Label Encoding -> Embedding)\n",
                "- **Wide Input**: `genres` (Multi-hot Encoding)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "step-2-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Users: 197270, Items: 42809, Genres: 20\n",
                        "Genre Classes: ['(no genres listed)' 'Action' 'Adventure' 'Animation' 'Children' 'Comedy'\n",
                        " 'Crime' 'Documentary' 'Drama' 'Fantasy' 'Film-Noir' 'Horror' 'IMAX'\n",
                        " 'Musical' 'Mystery' 'Romance' 'Sci-Fi' 'Thriller' 'War' 'Western']\n"
                    ]
                }
            ],
            "source": [
                "# 1. Deep Part: UserID, MovieID 인덱싱\n",
                "user_ids = data['userId'].unique()\n",
                "item_ids = data['movieId'].unique()\n",
                "\n",
                "user2idx = {u: i for i, u in enumerate(user_ids)}\n",
                "item2idx = {m: i for i, m in enumerate(item_ids)}\n",
                "\n",
                "data['user_idx'] = data['userId'].map(user2idx)\n",
                "data['item_idx'] = data['movieId'].map(item2idx)\n",
                "\n",
                "num_users = len(user_ids)\n",
                "num_items = len(item_ids)\n",
                "\n",
                "# 2. Wide Part: Genre Multi-hot Encoding\n",
                "# 장르 문자열을 리스트로 변환 ('Toy Story (1995)' -> ['Adventure', 'Animation', ...])\n",
                "data['genres_list'] = data['genres'].apply(lambda x: x.split('|'))\n",
                "\n",
                "mlb = MultiLabelBinarizer()\n",
                "genres_encoded = mlb.fit_transform(data['genres_list'])\n",
                "num_genres = len(mlb.classes_)\n",
                "\n",
                "# 데이터프레임에 장르 벡터 추가 (나중에 텐서로 변환하기 쉽게)\n",
                "# 주의: 데이터프레임에 리스트나 배열을 직접 넣으면 느려질 수 있으니, Dataset에서 처리하거나 여기서 미리 변환\n",
                "print(f\"Users: {num_users}, Items: {num_items}, Genres: {num_genres}\")\n",
                "print(f\"Genre Classes: {mlb.classes_}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step-3-md",
            "metadata": {},
            "source": [
                "### 3. Dataset & DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "step-3-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class WideAndDeepDataset(Dataset):\n",
                "    def __init__(self, df, genres_encoded):\n",
                "        self.users = torch.LongTensor(df['user_idx'].values)\n",
                "        self.items = torch.LongTensor(df['item_idx'].values)\n",
                "        self.ratings = torch.FloatTensor(df['rating'].values)\n",
                "        self.genres = torch.FloatTensor(genres_encoded)\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.users)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.users[idx], self.items[idx], self.genres[idx], self.ratings[idx]\n",
                "\n",
                "# Train/Val/Test Split\n",
                "# 인덱스를 나눠서 genres_encoded도 같이 나누기 위함\n",
                "train_idx, test_idx = train_test_split(range(len(data)), test_size=0.1, random_state=42)\n",
                "train_idx, val_idx = train_test_split(train_idx, test_size=0.111, random_state=42)\n",
                "\n",
                "train_df = data.iloc[train_idx]\n",
                "val_df = data.iloc[val_idx]\n",
                "test_df = data.iloc[test_idx]\n",
                "\n",
                "train_genres = genres_encoded[train_idx]\n",
                "val_genres = genres_encoded[val_idx]\n",
                "test_genres = genres_encoded[test_idx]\n",
                "\n",
                "train_ds = WideAndDeepDataset(train_df, train_genres)\n",
                "val_ds = WideAndDeepDataset(val_df, val_genres)\n",
                "test_ds = WideAndDeepDataset(test_df, test_genres)\n",
                "\n",
                "batch_size = 4096\n",
                "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
                "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step-4-md",
            "metadata": {},
            "source": [
                "### 4. Wide & Deep Model Architecture\n",
                "- **Wide**: Linear(num_genres -> 1)\n",
                "- **Deep**: Embedding(User) + Embedding(Item) -> MLP -> Linear( -> 1)\n",
                "- **Output**: Wide + Deep"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "step-4-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class WideAndDeep(nn.Module):\n",
                "    def __init__(self, num_users, num_items, num_genres, embed_dim=32, mlp_layers=[64, 32, 16]):\n",
                "        super().__init__()\n",
                "        \n",
                "        # --- Wide Part ---\n",
                "        # 장르(Multi-hot)를 입력받아 평점 예측에 기여\n",
                "        self.wide_linear = nn.Linear(num_genres, 1)\n",
                "        \n",
                "        # --- Deep Part ---\n",
                "        self.user_embedding = nn.Embedding(num_users, embed_dim)\n",
                "        self.item_embedding = nn.Embedding(num_items, embed_dim)\n",
                "        \n",
                "        mlp_modules = []\n",
                "        input_size = embed_dim * 2\n",
                "        for output_size in mlp_layers:\n",
                "            mlp_modules.append(nn.Linear(input_size, output_size))\n",
                "            mlp_modules.append(nn.ReLU())\n",
                "            mlp_modules.append(nn.Dropout(0.2))\n",
                "            input_size = output_size\n",
                "        self.deep_mlp = nn.Sequential(*mlp_modules)\n",
                "        self.deep_predict = nn.Linear(input_size, 1)\n",
                "        \n",
                "        self._init_weights()\n",
                "        \n",
                "    def _init_weights(self):\n",
                "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
                "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
                "        nn.init.xavier_uniform_(self.wide_linear.weight)\n",
                "        for m in self.deep_mlp:\n",
                "            if isinstance(m, nn.Linear):\n",
                "                nn.init.xavier_uniform_(m.weight)\n",
                "        nn.init.kaiming_uniform_(self.deep_predict.weight, a=1, nonlinearity='sigmoid')\n",
                "\n",
                "    def forward(self, users, items, genres):\n",
                "        # Wide\n",
                "        wide_out = self.wide_linear(genres)\n",
                "        \n",
                "        # Deep\n",
                "        u_emb = self.user_embedding(users)\n",
                "        i_emb = self.item_embedding(items)\n",
                "        deep_in = torch.cat([u_emb, i_emb], dim=1)\n",
                "        deep_features = self.deep_mlp(deep_in)\n",
                "        deep_out = self.deep_predict(deep_features)\n",
                "        \n",
                "        # Combine\n",
                "        return (wide_out + deep_out).squeeze()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step-5-md",
            "metadata": {},
            "source": [
                "### 5. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "step-5-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: mps\n",
                        "Epoch  1 | Train RMSE: 1.7443 | Val RMSE: 0.9131\n",
                        "  -> Saved Best Model\n",
                        "Epoch  2 | Train RMSE: 1.0625 | Val RMSE: 0.8934\n",
                        "  -> Saved Best Model\n",
                        "Epoch  3 | Train RMSE: 0.9802 | Val RMSE: 0.8871\n",
                        "  -> Saved Best Model\n",
                        "Epoch  4 | Train RMSE: 0.9246 | Val RMSE: 0.8867\n",
                        "  -> Saved Best Model\n",
                        "Epoch  5 | Train RMSE: 0.8791 | Val RMSE: 0.8868\n",
                        "Epoch  6 | Train RMSE: 0.8394 | Val RMSE: 0.8896\n",
                        "Epoch  7 | Train RMSE: 0.8074 | Val RMSE: 0.8938\n",
                        "Early Stopping\n"
                    ]
                }
            ],
            "source": [
                "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "model = WideAndDeep(num_users, num_items, num_genres).to(device)\n",
                "criterion = nn.MSELoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "epochs = 10\n",
                "best_val_rmse = float('inf')\n",
                "patience = 3\n",
                "counter = 0\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    train_loss = 0\n",
                "    for users, items, genres, ratings in train_loader:\n",
                "        users, items, genres, ratings = users.to(device), items.to(device), genres.to(device), ratings.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(users, items, genres)\n",
                "        loss = criterion(outputs, ratings)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        train_loss += loss.item() * users.size(0)\n",
                "        \n",
                "    train_rmse = (train_loss / len(train_ds)) ** 0.5\n",
                "    \n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    with torch.no_grad():\n",
                "        for users, items, genres, ratings in val_loader:\n",
                "            users, items, genres, ratings = users.to(device), items.to(device), genres.to(device), ratings.to(device)\n",
                "            outputs = model(users, items, genres)\n",
                "            val_loss += criterion(outputs, ratings).item() * users.size(0)\n",
                "    val_rmse = (val_loss / len(val_ds)) ** 0.5\n",
                "    \n",
                "    print(f\"Epoch {epoch+1:2d} | Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f}\")\n",
                "    \n",
                "    if val_rmse < best_val_rmse:\n",
                "        best_val_rmse = val_rmse\n",
                "        torch.save(model.state_dict(), '../models/wide_deep_model.pth')\n",
                "        counter = 0\n",
                "        print(\"  -> Saved Best Model\")\n",
                "    else:\n",
                "        counter += 1\n",
                "        if counter >= patience:\n",
                "            print(\"Early Stopping\")\n",
                "            break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "step-6-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test RMSE: 0.8881\n"
                    ]
                }
            ],
            "source": [
                "# Final Evaluation\n",
                "model.load_state_dict(torch.load('../models/wide_deep_model.pth'))\n",
                "model.eval()\n",
                "test_loss = 0\n",
                "with torch.no_grad():\n",
                "    for users, items, genres, ratings in test_loader:\n",
                "        users, items, genres, ratings = users.to(device), items.to(device), genres.to(device), ratings.to(device)\n",
                "        outputs = model(users, items, genres)\n",
                "        test_loss += criterion(outputs, ratings).item() * users.size(0)\n",
                "print(f\"Test RMSE: {(test_loss / len(test_ds))**0.5:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
