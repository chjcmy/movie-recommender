{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncf-import-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 로드\n",
    "ratings = pd.read_csv('../data/ratings.csv')\n",
    "\n",
    "# userId와 movieId를 0부터 시작하는 정수 인덱스로 변환\n",
    "user_ids = ratings['userId'].unique()\n",
    "item_ids = ratings['movieId'].unique()\n",
    "user2idx = {u: i for i, u in enumerate(user_ids)}\n",
    "item2idx = {m: i for i, m in enumerate(item_ids)}\n",
    "\n",
    "ratings['user_idx'] = ratings['userId'].map(user2idx)\n",
    "ratings['item_idx'] = ratings['movieId'].map(item2idx)\n",
    "\n",
    "num_users = len(user_ids)\n",
    "num_items = len(item_ids)\n",
    "print(f\"Users: {num_users}, Items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncf-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test 분리 (MF와 동일한 비율)\n",
    "train_val, test = train_test_split(ratings, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.111, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train)}, Validation: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncf-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.LongTensor(df['user_idx'].values)\n",
    "        self.items = torch.LongTensor(df['item_idx'].values)\n",
    "        self.ratings = torch.FloatTensor(df['rating'].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "train_ds = NCFDataset(train)\n",
    "val_ds = NCFDataset(val)\n",
    "test_ds = NCFDataset(test)\n",
    "\n",
    "batch_size = 1024\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncf-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embed_dim=32, mlp_layers=[64, 32, 16]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # GMF Part\n",
    "        self.gmf_user_embedding = nn.Embedding(num_users, embed_dim)\n",
    "        self.gmf_item_embedding = nn.Embedding(num_items, embed_dim)\n",
    "        \n",
    "        # MLP Part\n",
    "        self.mlp_user_embedding = nn.Embedding(num_users, embed_dim)\n",
    "        self.mlp_item_embedding = nn.Embedding(num_items, embed_dim)\n",
    "        \n",
    "        mlp_modules = []\n",
    "        input_size = embed_dim * 2\n",
    "        for output_size in mlp_layers:\n",
    "            mlp_modules.append(nn.Linear(input_size, output_size))\n",
    "            mlp_modules.append(nn.ReLU())\n",
    "            mlp_modules.append(nn.Dropout(0.2))\n",
    "            input_size = output_size\n",
    "        self.mlp_layers = nn.Sequential(*mlp_modules)\n",
    "        \n",
    "        # Final Prediction Layer\n",
    "        # GMF output (embed_dim) + MLP output (last layer size)\n",
    "        predict_input_size = embed_dim + mlp_layers[-1]\n",
    "        self.predict_layer = nn.Linear(predict_input_size, 1)\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.gmf_user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.gmf_item_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.mlp_user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.mlp_item_embedding.weight, std=0.01)\n",
    "        \n",
    "        for m in self.mlp_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.predict_layer.weight, a=1, nonlinearity='sigmoid')\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        # GMF\n",
    "        gmf_u = self.gmf_user_embedding(users)\n",
    "        gmf_i = self.gmf_item_embedding(items)\n",
    "        gmf_out = gmf_u * gmf_i\n",
    "        \n",
    "        # MLP\n",
    "        mlp_u = self.mlp_user_embedding(users)\n",
    "        mlp_i = self.mlp_item_embedding(items)\n",
    "        mlp_in = torch.cat([mlp_u, mlp_i], dim=1)\n",
    "        mlp_out = self.mlp_layers(mlp_in)\n",
    "        \n",
    "        # Concatenate and Predict\n",
    "        concat = torch.cat([gmf_out, mlp_out], dim=1)\n",
    "        out = self.predict_layer(concat)\n",
    "        \n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncf-train-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = NCF(num_users, num_items, embed_dim=32).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncf-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "best_val_rmse = float('inf')\n",
    "patience = 3\n",
    "counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for users, items, ratings in train_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(users, items)\n",
    "        loss = criterion(preds, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * users.size(0)\n",
    "    \n",
    "    train_rmse = (train_loss / len(train_ds)) ** 0.5\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in val_loader:\n",
    "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "            preds = model(users, items)\n",
    "            val_loss += criterion(preds, ratings).item() * users.size(0)\n",
    "    \n",
    "    val_rmse = (val_loss / len(val_ds)) ** 0.5\n",
    "    print(f\"Epoch {epoch+1:2d} | Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f}\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        counter = 0\n",
    "        print(\"  -> New Best Model!\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"  -> No improvement ({counter}/{patience})\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early Stopping!\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncf-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Evaluation\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for users, items, ratings in test_loader:\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        preds = model(users, items)\n",
    "        test_loss += criterion(preds, ratings).item() * users.size(0)\n",
    "\n",
    "test_rmse = (test_loss / len(test_ds)) ** 0.5\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
