{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "step-1-md",
            "metadata": {},
            "source": [
                "# SASRec (Self-Attentive Sequential Recommendation) Implementation\n",
                "\n",
                "이 노트북에서는 **SASRec** 모델을 구현합니다.\n",
                "- **핵심 아이디어**: 유저가 과거에 본 영화들의 **순서(Sequence)**를 보고, 다음에 볼 영화를 예측합니다.\n",
                "- **구조**: Transformer의 Self-Attention 메커니즘을 사용하여 시퀀스 내의 패턴을 파악합니다.\n",
                "\n",
                "### 1. 데이터 로드 및 시퀀스 생성"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "step-1-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Users: 20094, Items: 40295\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>userId</th>\n",
                            "      <th>item_idx</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>[135, 138, 132, 140, 131, 24, 31, 49, 62, 70, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>8</td>\n",
                            "      <td>[144, 23, 147, 65, 26, 148, 128, 151, 153, 162...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>14</td>\n",
                            "      <td>[185, 165, 191, 166, 179, 188, 177, 171, 169, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>31</td>\n",
                            "      <td>[193, 243, 161, 245, 242, 244, 201, 203, 233, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>32</td>\n",
                            "      <td>[284, 253, 283, 254, 268, 269, 282, 260, 264, ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   userId                                           item_idx\n",
                            "0       1  [135, 138, 132, 140, 131, 24, 31, 49, 62, 70, ...\n",
                            "1       8  [144, 23, 147, 65, 26, 148, 128, 151, 153, 162...\n",
                            "2      14  [185, 165, 191, 166, 179, 188, 177, 171, 169, ...\n",
                            "3      31  [193, 243, 161, 245, 242, 244, 201, 203, 233, ...\n",
                            "4      32  [284, 253, 283, 254, 268, 269, 282, 260, 264, ..."
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# 1. 데이터 로드\n",
                "ratings = pd.read_csv('../data/ratings.csv')\n",
                "\n",
                "# 2. 데이터 샘플링 (속도를 위해 10%만 사용)\n",
                "# 주의: 시퀀스 모델은 유저별 기록이 중요하므로, 유저 단위로 샘플링하는 것이 좋음\n",
                "user_ids = ratings['userId'].unique()\n",
                "sample_user_ids = np.random.choice(user_ids, size=int(len(user_ids) * 0.1), replace=False)\n",
                "ratings = ratings[ratings['userId'].isin(sample_user_ids)].copy()\n",
                "\n",
                "# 3. 인덱싱 (0은 Padding용으로 비워둠 -> 1부터 시작)\n",
                "item_ids = ratings['movieId'].unique()\n",
                "item2idx = {m: i+1 for i, m in enumerate(item_ids)}\n",
                "ratings['item_idx'] = ratings['movieId'].map(item2idx)\n",
                "num_items = len(item_ids) + 1 # 0번은 padding\n",
                "\n",
                "# 4. 시퀀스 생성 (User별로 시간순 정렬 후 영화 리스트 만들기)\n",
                "ratings = ratings.sort_values(['userId', 'timestamp'])\n",
                "user_group = ratings.groupby('userId')['item_idx'].apply(list).reset_index()\n",
                "\n",
                "print(f\"Users: {len(user_group)}, Items: {num_items}\")\n",
                "user_group.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step-2-md",
            "metadata": {},
            "source": [
                "### 2. Dataset & DataLoader\n",
                "- **Input**: `[영화1, 영화2, 영화3, ..., 영화N-1]`\n",
                "- **Target**: `[영화2, 영화3, 영화4, ..., 영화N]` (한 칸씩 밀린 것)\n",
                "- **Padding**: 시퀀스 길이를 맞추기 위해 앞부분을 0으로 채움"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "step-2-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SASRecDataset(Dataset):\n",
                "    def __init__(self, user_sequences, max_len=50):\n",
                "        self.user_sequences = user_sequences\n",
                "        self.max_len = max_len\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.user_sequences)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        seq = self.user_sequences[idx]\n",
                "        \n",
                "        # 시퀀스 길이 맞추기 (Truncate or Pad)\n",
                "        # 마지막 아이템은 '정답'으로 쓸 거라 제외하고 입력으로 씀\n",
                "        # 학습 때는 (입력: 0~N-1, 정답: 1~N) 방식으로 전체를 다 씀\n",
                "        \n",
                "        seq_len = len(seq)\n",
                "        if seq_len < self.max_len + 1:\n",
                "            # 패딩 (앞쪽에 0 채우기)\n",
                "            pad_len = self.max_len + 1 - seq_len\n",
                "            seq = [0] * pad_len + seq\n",
                "        else:\n",
                "            # 자르기 (최신 데이터 위주로)\n",
                "            seq = seq[-(self.max_len + 1):]\n",
                "            \n",
                "        # Input: 처음 ~ 마지막-1\n",
                "        # Target: 두번째 ~ 마지막\n",
                "        input_seq = torch.LongTensor(seq[:-1])\n",
                "        target_seq = torch.LongTensor(seq[1:])\n",
                "        \n",
                "        return input_seq, target_seq\n",
                "\n",
                "# Train/Val Split\n",
                "train_seqs, val_seqs = train_test_split(user_group['item_idx'].tolist(), test_size=0.1, random_state=42)\n",
                "\n",
                "max_len = 50\n",
                "train_ds = SASRecDataset(train_seqs, max_len=max_len)\n",
                "val_ds = SASRecDataset(val_seqs, max_len=max_len)\n",
                "\n",
                "batch_size = 128\n",
                "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step-3-md",
            "metadata": {},
            "source": [
                "### 3. SASRec Model Architecture\n",
                "- **Embedding**: Item Embedding + Position Embedding\n",
                "- **Transformer Block**: Self-Attention -> LayerNorm -> FeedForward -> LayerNorm\n",
                "- **Prediction**: Output * Item Embedding (Dot Product)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "step-3-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SASRec(nn.Module):\n",
                "    def __init__(self, num_items, max_len, embed_dim=64, num_heads=2, num_layers=2, dropout=0.1):\n",
                "        super().__init__()\n",
                "        self.num_items = num_items\n",
                "        self.max_len = max_len\n",
                "        \n",
                "        # Embeddings\n",
                "        self.item_embedding = nn.Embedding(num_items, embed_dim, padding_idx=0)\n",
                "        self.position_embedding = nn.Embedding(max_len, embed_dim)\n",
                "        \n",
                "        # Transformer Encoder\n",
                "        encoder_layer = nn.TransformerEncoderLayer(\n",
                "            d_model=embed_dim, \n",
                "            nhead=num_heads, \n",
                "            dim_feedforward=embed_dim*4, \n",
                "            dropout=dropout,\n",
                "            batch_first=True, # (Batch, Seq, Feature)\n",
                "            norm_first=True   # Pre-LayerNorm (학습 안정성)\n",
                "        )\n",
                "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
                "        \n",
                "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        \n",
                "        self._init_weights()\n",
                "        \n",
                "    def _init_weights(self):\n",
                "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
                "        nn.init.xavier_uniform_(self.position_embedding.weight)\n",
                "\n",
                "    def forward(self, input_seq):\n",
                "        # input_seq: (Batch, Max_Len)\n",
                "        batch_size = input_seq.size(0)\n",
                "        seq_len = input_seq.size(1)\n",
                "        \n",
                "        # Masking (Padding은 무시하도록)\n",
                "        # True면 무시(masking)됨. 0인 부분이 True가 되도록 설정\n",
                "        src_key_padding_mask = (input_seq == 0)\n",
                "        \n",
                "        # Causal Mask (미래 정보 참조 금지)\n",
                "        # 대각선 위쪽을 -inf로 채움\n",
                "        src_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(input_seq.device)\n",
                "        \n",
                "        # Embedding\n",
                "        items = self.item_embedding(input_seq)\n",
                "        positions = self.position_embedding(torch.arange(seq_len, device=input_seq.device))\n",
                "        x = items + positions\n",
                "        x = self.dropout(x)\n",
                "        \n",
                "        # Transformer\n",
                "        # src_mask: 미래 참조 방지\n",
                "        # src_key_padding_mask: 패딩 무시\n",
                "        out = self.transformer_encoder(x, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
                "        out = self.layer_norm(out)\n",
                "        \n",
                "        # Prediction (모든 아이템과의 내적)\n",
                "        # (Batch, Seq, Dim) * (Num_Items, Dim)^T -> (Batch, Seq, Num_Items)\n",
                "        logits = torch.matmul(out, self.item_embedding.weight.transpose(0, 1))\n",
                "        \n",
                "        return logits"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step-4-md",
            "metadata": {},
            "source": [
                "### 4. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "step-4-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: mps\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/choeseonghyeon/WebstormProjects/movie-recommender/backend/venv/lib/python3.13/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
                        "  warnings.warn(\n",
                        "/Users/choeseonghyeon/WebstormProjects/movie-recommender/backend/venv/lib/python3.13/site-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch  1 | Train Loss: 8.3660 | Val Loss: 7.8820\n",
                        "  -> Saved Best Model\n",
                        "Epoch  2 | Train Loss: 7.7230 | Val Loss: 7.6272\n",
                        "  -> Saved Best Model\n",
                        "Epoch  3 | Train Loss: 7.3684 | Val Loss: 7.2180\n",
                        "  -> Saved Best Model\n",
                        "Epoch  4 | Train Loss: 7.1008 | Val Loss: 7.0200\n",
                        "  -> Saved Best Model\n",
                        "Epoch  5 | Train Loss: 6.9097 | Val Loss: 6.8641\n",
                        "  -> Saved Best Model\n",
                        "Epoch  6 | Train Loss: 6.7813 | Val Loss: 6.7826\n",
                        "  -> Saved Best Model\n",
                        "Epoch  7 | Train Loss: 6.6884 | Val Loss: 6.7126\n",
                        "  -> Saved Best Model\n",
                        "Epoch  8 | Train Loss: 6.6009 | Val Loss: 6.6454\n",
                        "  -> Saved Best Model\n",
                        "Epoch  9 | Train Loss: 6.5180 | Val Loss: 6.5917\n",
                        "  -> Saved Best Model\n",
                        "Epoch 10 | Train Loss: 6.4452 | Val Loss: 6.5429\n",
                        "  -> Saved Best Model\n"
                    ]
                }
            ],
            "source": [
                "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "model = SASRec(num_items, max_len).to(device)\n",
                "criterion = nn.CrossEntropyLoss(ignore_index=0) # Padding(0)은 Loss 계산 제외\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "epochs = 10\n",
                "best_val_loss = float('inf')\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    train_loss = 0\n",
                "    \n",
                "    for input_seq, target_seq in train_loader:\n",
                "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        logits = model(input_seq)\n",
                "        \n",
                "        # Loss 계산을 위해 차원 변경\n",
                "        # logits: (Batch, Seq, Num_Items) -> (Batch*Seq, Num_Items)\n",
                "        # target: (Batch, Seq) -> (Batch*Seq)\n",
                "        loss = criterion(logits.view(-1, num_items), target_seq.view(-1))\n",
                "        \n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        train_loss += loss.item()\n",
                "        \n",
                "    avg_train_loss = train_loss / len(train_loader)\n",
                "    \n",
                "    # Validation\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    with torch.no_grad():\n",
                "        for input_seq, target_seq in val_loader:\n",
                "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
                "            logits = model(input_seq)\n",
                "            loss = criterion(logits.view(-1, num_items), target_seq.view(-1))\n",
                "            val_loss += loss.item()\n",
                "            \n",
                "    avg_val_loss = val_loss / len(val_loader)\n",
                "    \n",
                "    print(f\"Epoch {epoch+1:2d} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
                "    \n",
                "    if avg_val_loss < best_val_loss:\n",
                "        best_val_loss = avg_val_loss\n",
                "        torch.save(model.state_dict(), '../models/sasrec_model.pth')\n",
                "        print(\"  -> Saved Best Model\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "step-5-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Input Sequence (Last 5): [np.int64(79132), np.int64(48082), np.int64(778), np.int64(44694), np.int64(1617)]\n",
                        "Recommended Top 10:\n",
                        "Movie ID: 7361\n",
                        "Movie ID: 44555\n",
                        "Movie ID: 4973\n",
                        "Movie ID: 4226\n",
                        "Movie ID: 55820\n",
                        "Movie ID: 1089\n",
                        "Movie ID: 296\n",
                        "Movie ID: 1193\n",
                        "Movie ID: 1213\n",
                        "Movie ID: 6016\n"
                    ]
                }
            ],
            "source": [
                "# Inference Example\n",
                "# 마지막 시퀀스를 넣었을 때, 그 다음 나올 아이템(영화) Top 10 예측\n",
                "\n",
                "model.load_state_dict(torch.load('../models/sasrec_model.pth'))\n",
                "model.eval()\n",
                "\n",
                "def recommend(user_seq, k=10):\n",
                "    # 전처리 (Padding/Truncate)\n",
                "    seq_len = len(user_seq)\n",
                "    if seq_len < max_len:\n",
                "        pad_len = max_len - seq_len\n",
                "        seq = [0] * pad_len + user_seq\n",
                "    else:\n",
                "        seq = user_seq[-max_len:]\n",
                "        \n",
                "    input_tensor = torch.LongTensor([seq]).to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        logits = model(input_tensor)\n",
                "        # 마지막 시점(Last Time Step)의 예측값만 가져오기\n",
                "        last_logits = logits[0, -1, :] # (Num_Items,)\n",
                "        \n",
                "        # Top K\n",
                "        top_k_vals, top_k_indices = torch.topk(last_logits, k)\n",
                "        \n",
                "    return top_k_indices.cpu().numpy()\n",
                "\n",
                "# 테스트용 유저 한 명 (Validation Set에서)\n",
                "test_seq = val_seqs[0]\n",
                "recommended_indices = recommend(test_seq)\n",
                "\n",
                "# 인덱스 -> 영화 ID 변환을 위한 역매핑\n",
                "idx2item = {v: k for k, v in item2idx.items()}\n",
                "\n",
                "print(f\"Input Sequence (Last 5): {[idx2item.get(i, 'Pad') for i in test_seq[-5:]]}\")\n",
                "print(\"Recommended Top 10:\")\n",
                "for idx in recommended_indices:\n",
                "    if idx == 0: continue\n",
                "    print(f\"Movie ID: {idx2item[idx]}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
