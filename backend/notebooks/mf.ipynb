{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "2b802412-f9ab-4444-a733-337cf896afd0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# (경로를 실제 ratings.csv 위치로 바꿔주세요)\n",
                "ratings = pd.read_csv('../data/ratings.csv')\n",
                "\n",
                "# userId와 movieId를 0부터 시작하는 정수 인덱스(user_idx, item_idx)로 변환\n",
                "user_ids = ratings['userId'].unique()\n",
                "item_ids = ratings['movieId'].unique()\n",
                "user2idx = {u: i for i, u in enumerate(user_ids)}\n",
                "item2idx = {m: i for i, m in enumerate(item_ids)}\n",
                "\n",
                "ratings['user_idx'] = ratings['userId'].map(user2idx)\n",
                "ratings['item_idx'] = ratings['movieId'].map(item2idx)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2b01e1ce-acc3-4c81-a42b-0681bee36649",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train: 25603362, Validation: 3196821, Test: 3200021\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# 먼저 train+val과 test로 분리 (test: 전체의 10%)\n",
                "train_val, test = train_test_split(ratings, test_size=0.1, random_state=42)\n",
                "\n",
                "# train과 validation으로 분리 (전체의 10%가 validation)\n",
                "train, val = train_test_split(train_val, test_size=0.111, random_state=42)\n",
                "\n",
                "print(f\"Train: {len(train)}, Validation: {len(val)}, Test: {len(test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "c72d422d-a8a0-4145-bdaf-1dc1cf342e2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "class MFDataset(Dataset):\n",
                "    def __init__(self, df):\n",
                "        self.users = torch.LongTensor(df['user_idx'].values)\n",
                "        self.items = torch.LongTensor(df['item_idx'].values)\n",
                "        self.ratings = torch.FloatTensor(df['rating'].values)\n",
                "    def __len__(self):\n",
                "        return len(self.ratings)\n",
                "    def __getitem__(self, idx):\n",
                "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
                "\n",
                "train_ds = MFDataset(train)\n",
                "val_ds = MFDataset(val)\n",
                "test_ds = MFDataset(test)\n",
                "\n",
                "train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=1024)\n",
                "test_loader = DataLoader(test_ds, batch_size=1024)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "e7da9f43-e36e-4fb4-b8b7-db6cf1936957",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "\n",
                "class MF(nn.Module):\n",
                "    def __init__(self, num_users, num_items, embed_dim=32):\n",
                "        super().__init__()\n",
                "        self.user_embedding = nn.Embedding(num_users, embed_dim)\n",
                "        self.item_embedding = nn.Embedding(num_items, embed_dim)\n",
                "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
                "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
                "    def forward(self, users, items):\n",
                "        u = self.user_embedding(users)\n",
                "        i = self.item_embedding(items)\n",
                "        return (u * i).sum(1)  # user, item 임베딩의 내적값내적값"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "079cfd10-11c9-42e4-a6cf-18d4ba8b2eaf",
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
                "num_users = ratings['user_idx'].nunique()\n",
                "num_items = ratings['item_idx'].nunique()\n",
                "epochs = 10            # 실험을 위해 5회, 실제로는 10~30까지 늘릴 수 있음\n",
                "model = MF(num_users, num_items, embed_dim=32).to(device)\n",
                "criterion = nn.MSELoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "2923b987-c33d-4d73-80fb-a60b37484f91",
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1 | Validation RMSE: 0.9057\n",
                        "  → 새로운 최고 성능! 모델 저장\n",
                        "Epoch 2 | Validation RMSE: 0.8488\n",
                        "  → 새로운 최고 성능! 모델 저장\n",
                        "Epoch 3 | Validation RMSE: 0.8163\n",
                        "  → 새로운 최고 성능! 모델 저장\n",
                        "Epoch 4 | Validation RMSE: 0.8003\n",
                        "  → 새로운 최고 성능! 모델 저장\n",
                        "Epoch 5 | Validation RMSE: 0.7961\n",
                        "  → 새로운 최고 성능! 모델 저장\n",
                        "Epoch 6 | Validation RMSE: 0.7969\n",
                        "  → 개선 없음 (1/3)\n",
                        "Epoch 7 | Validation RMSE: 0.7987\n",
                        "  → 개선 없음 (2/3)\n",
                        "Epoch 8 | Validation RMSE: 0.8011\n",
                        "  → 개선 없음 (3/3)\n",
                        "Early stopping! 최고 성능: 0.7961\n"
                    ]
                }
            ],
            "source": [
                "# Early stopping 설정\n",
                "best_val_rmse = float('inf')\n",
                "patience = 3  # 3 epoch 동안 개선 없으면 중단\n",
                "counter = 0\n",
                "best_model_state = None\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    for users, items, ratings in train_loader:\n",
                "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        preds = model(users, items)\n",
                "        loss = criterion(preds, ratings)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "    \n",
                "    # validation 평가\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    with torch.no_grad():\n",
                "        for users, items, ratings in val_loader:\n",
                "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
                "            preds = model(users, items)\n",
                "            val_loss += criterion(preds, ratings).item() * users.size(0)\n",
                "    val_loss = val_loss / len(val_ds)\n",
                "    val_rmse = val_loss**0.5\n",
                "    print(f\"Epoch {epoch + 1} | Validation RMSE: {val_rmse:.4f}\")\n",
                "    \n",
                "    # Early stopping 체크\n",
                "    if val_rmse < best_val_rmse:\n",
                "        best_val_rmse = val_rmse\n",
                "        best_model_state = model.state_dict().copy()  # 최고 모델 저장\n",
                "        counter = 0\n",
                "        print(f\"  → 새로운 최고 성능! 모델 저장\")\n",
                "    else:\n",
                "        counter += 1\n",
                "        print(f\"  → 개선 없음 ({counter}/{patience})\")\n",
                "        if counter >= patience:\n",
                "            print(f\"Early stopping! 최고 성능: {best_val_rmse:.4f}\")\n",
                "            model.load_state_dict(best_model_state)  # 최고 모델 복원\n",
                "            break\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "ec3de252-b3c2-4e21-a8bf-1a14238de84c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test RMSE: 0.8016\n"
                    ]
                }
            ],
            "source": [
                "model.eval()\n",
                "test_loss = 0\n",
                "with torch.no_grad():\n",
                "    for users, items, ratings in test_loader:\n",
                "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
                "        preds = model(users, items)\n",
                "        test_loss += criterion(preds, ratings).item() * users.size(0)\n",
                "test_loss = test_loss / len(test_ds)\n",
                "print(f\"Test RMSE: {test_loss**0.5:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "save-model",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MF Model saved to ../models/mf_model.pth\n"
                    ]
                }
            ],
            "source": [
                "# 모델 저장\n",
                "torch.save(model.state_dict(), '../models/mf_model.pth')\n",
                "print(\"MF Model saved to ../models/mf_model.pth\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
