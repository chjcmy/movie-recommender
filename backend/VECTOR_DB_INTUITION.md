# Vector DB (벡터 데이터베이스) 필요성 가이드

"지금 내 프로젝트(영화 4만 개)에서 벡터 DB가 필요할까?"
결론부터 말씀드리면 **"기능적으로는 불필요하지만, 포트폴리오용으로는 아주 좋습니다."**

## 1. 왜 기능적으로는 불필요한가요? (Scale 문제)

현재 우리 프로젝트의 영화 개수는 약 **40,000개**입니다.
컴퓨터 입장에서 4만 개의 벡터 내적(Dot Product)을 계산하는 건 **"눈 깜짝할 새(0.01초 미만)"**에 끝납니다.

### 비교: Brute Force vs Vector DB (ANN)

| 구분 | Brute Force (현재 방식) | Vector DB (ANN) |
| :--- | :--- | :--- |
| **방식** | 4만 개를 **다 계산해서** 1등을 찾음 | 지름길을 써서 **대충 근처**를 뒤짐 |
| **정확도** | **100%** (무조건 정확함) | **99%** (가끔 틀릴 수 있음) |
| **속도** | 4만 개일 때: **빠름** (0.005초)<br>1억 개일 때: **느림** (10초) | 4만 개일 때: **비슷함**<br>1억 개일 때: **빠름** (0.01초) |
| **비용** | 메모리 조금 씀 | 별도 서버/인프라 필요 |

> **결론**: 데이터가 100만 개, 1000만 개를 넘어갈 때 Vector DB의 진가가 발휘됩니다. 4만 개는 파이썬(`numpy/torch`)이 그냥 씹어먹습니다.

## 2. 그럼에도 불구하고 왜 쓰면 좋을까요? (Portfolio)

면접관이 **"데이터가 1,000만 개로 늘어나면 어떻게 할 건가요?"**라고 물어볼 것이기 때문입니다.

이때 **"그래서 저는 미리 확장성을 고려해 `pgvector`나 `Milvus`를 도입해봤습니다."**라고 대답하면 합격 시그널입니다.

## 3. 추천하는 방법: `pgvector` (PostgreSQL 확장)

이미 PostgreSQL을 쓰고 계시니, 굳이 다른 DB(Pinecone, Milvus)를 또 띄울 필요 없이 **PostgreSQL 안에 벡터 검색 기능을 추가**하는 것이 베스트입니다.

### 구현 시나리오
1.  PostgreSQL에 `pgvector` 익스텐션 설치.
2.  `Movie` 테이블에 `embedding` 컬럼 추가 (벡터 저장).
3.  SQL로 검색: `SELECT * FROM movies ORDER BY embedding <-> '[0.1, 0.5, ...]' LIMIT 10;`
4.  Django에서 `django-pgvector` 라이브러리로 쉽게 사용 가능.
## 5. Q&A: "하지만 임베딩 된 걸 어디에 쓸 것이냐, 이것도 문제야"

**"저장해봤자 쓸 데가 없으면 짐"**이죠. 정확한 지적입니다.
임베딩을 DB에 저장해두면 다음과 같은 **"고급 기능"**들을 구현할 수 있습니다.

### 1. "이 영화와 비슷한 영화" (Item-to-Item Recommendation)
-   **상황**: 사용자가 `아이언맨` 상세 페이지에 들어갔습니다.
-   **활용**: `아이언맨`의 임베딩 벡터를 꺼내서, 가장 가까운 벡터 5개를 찾습니다.
-   **결과**: `어벤져스`, `캡틴 아메리카`, `트랜스포머`... 가 즉시 뜹니다.
-   **장점**: 모델을 매번 돌릴 필요 없이, **미리 계산된 벡터 거리**만 재면 되니까 엄청 빠릅니다.

### 2. "느낌으로 검색하기" (Semantic Search)
-   **상황**: 사용자가 "가슴이 웅장해지는 우주 영화"라고 검색했습니다.
-   **활용**: 검색어("가슴이 웅장해지는...")를 임베딩으로 바꾼 뒤, 영화 임베딩과 비교합니다.
-   **결과**: 제목에 단어가 없어도 `인터스텔라`, `그래비티`가 나옵니다.
-   **장점**: 키워드 매칭(SQL `LIKE`)의 한계를 넘어섭니다.

### 3. 실시간 유저 취향 반영 (Real-time Personalization)
-   **상황**: 유저가 방금 `로맨스` 영화 3개를 연달아 클릭했습니다.
-   **활용**: 유저의 현재 벡터를 `(영화1 + 영화2 + 영화3) / 3`으로 즉시 업데이트하고 검색합니다.
-   **결과**: 메인 화면이 갑자기 `로맨스` 위주로 바뀝니다.
-   **장점**: 모델 재학습(Training) 없이도 **실시간성**을 확보할 수 있습니다.

### 요약
임베딩을 저장한다는 건, **"영화의 DNA를 추출해서 보관해두는 것"**과 같습니다.
이 DNA가 있으면 **복제(비슷한 영화 찾기)**, **친자 확인(검색)**, **합성(취향 분석)** 등 할 수 있는 게 무궁무진해집니다.

## 6. Q&A: "그럼 모델마다 임베딩 된 걸 각각 저장해야 되는 거지? 같은 영화라도?"

**네, 맞습니다!** 아주 중요한 포인트를 짚으셨습니다.

### 1. 왜 따로 저장해야 하나요? (DNA가 다름)
각 모델은 영화를 **"바라보는 관점"**이 다릅니다.

-   **MF 모델**: "이 영화는 **별점 4점짜리**야." (점수 관점)
-   **SASRec 모델**: "이 영화는 **해리포터 1 다음에 보는 영화**야." (순서 관점)
-   **Wide & Deep**: "이 영화는 **액션 장르이고 20대 남자가 좋아해**." (특징 관점)

그래서 MF가 만든 벡터를 SASRec에 넣으면 **해석 불가(외계어)**가 됩니다.

### 2. 그럼 DB에 어떻게 저장하나요?
보통 두 가지 방법을 씁니다.

#### 방법 A: "대장 하나만 저장한다" (현실적)
가장 성능이 좋거나 범용적인 모델(예: SASRec 또는 BERT4Rec)의 임베딩 **하나만** 저장해서 씁니다.
-   `embedding` 컬럼 (SASRec 버전)

#### 방법 B: "다 저장한다" (욕심쟁이)
목적에 따라 골라 쓰기 위해 컬럼을 나눕니다.
-   `embedding_mf`: 별점 예측용
-   `embedding_sasrec`: 다음 영화 추천용

### 요약
같은 "아이언맨"이라도, **MF가 본 아이언맨**과 **SASRec이 본 아이언맨**은 다릅니다.
마치 **"한국어 설명"**과 **"영어 설명"**이 다른 것처럼, 모델마다 각자의 언어(벡터)로 저장해야 합니다.

## 7. Q&A: "그럼 그냥 모델을 돌리는 게 낫지 않아?"

**"속도"** 때문에 둘 다 씁니다. 이것이 바로 현업의 **국룰(Standard)**인 **"2단 추천 구조"**입니다.

### 1. 문제 상황: 영화가 1억 개라면?
유저가 들어올 때마다 1억 개 영화에 대해 모델을 다 돌린다?
-   **시간**: 10초 걸림 (유저 다 도망감)
-   **비용**: GPU 서버 수백 대 필요 (회사 망함)

### 2. 해결책: 2단계 작전 (Retrieval + Ranking)

#### 1단계: 후보 추리기 (Retrieval) -> "벡터 DB" 사용
-   **역할**: "일단 대충 비슷한 거 100개만 가져와 봐."
-   **방법**: 미리 저장된 **임베딩**으로 거리 계산.
-   **속도**: **0.01초** (엄청 빠름)
-   **정확도**: 90점 (조금 부정확해도 됨)

#### 2단계: 줄 세우기 (Ranking) -> "모델(Inference)" 사용
-   **역할**: "이 100개 중에서 진짜 유저가 좋아할 순서대로 줄 세워."
-   **방법**: **SASRec/Wide&Deep 모델**을 실시간으로 돌림.
-   **속도**: 0.1초 (1억 개는 못 돌려도, 100개는 금방 돌림)
-   **정확도**: **99점** (초정밀)

### 요약
-   **벡터 DB**: "전체 데이터에서 **후보**를 빠르게 뽑을 때" 씁니다. (예선전)
-   **모델**: "뽑힌 후보들 중에서 **최종 순위**를 정할 때" 씁니다. (결승전)

## 8. Q&A: "아, 그러니까 비슷한 영화는 벡터 DB, 추천은 모델? 그 소리인가?"

**90% 정답입니다!** 아주 깔끔한 정리입니다.
조금 더 정확하게 구분해 드리겠습니다.

### 상황별 도구 선택 가이드

| 상황 | 사용 도구 | 이유 |
| :--- | :--- | :--- |
| **1. "이 영화랑 비슷한 거 보여줘"**<br>(Item-to-Item) | **벡터 DB** | 정답이 정해져 있음(거리).<br>모델 돌릴 필요 없이 벡터 거리만 재면 됨. |
| **2. "철수한테 영화 추천해줘"**<br>(User-to-Item) | **모델 (Inference)** | 철수의 취향은 복잡함(순서, 상황).<br>모델이 머리를 써서 계산해야 함. |
| **3. "철수한테 추천할 건데, 영화가 1억 개야"**<br>(Large Scale Rec) | **벡터 DB + 모델** | 1. **벡터 DB**로 100개 후보 뽑기 (예선)<br>2. **모델**로 100개 줄 세우기 (결승) |

### 한 줄 요약
-   **벡터 DB**: **"미리 계산된 답지"**를 빨리 찾아올 때 씁니다. (비슷한 영화)
-   **모델**: **"그때그때 풀어야 하는 문제"**를 풀 때 씁니다. (유저 맞춤 추천)

## 4. 요약
## 9. Q&A: "일단 지금 프로젝트에서 벡터 디비를 쓸 수 있는지 알고 싶은 거야"

**네, 100% 쓸 수 있습니다!**

지금 `SQLite`를 쓰고 계시죠?
DB를 안 바꾸고 **"지금 당장"** 쓸 수 있는 방법이 있습니다.

### [추천] 가장 현실적인 방법: "SQLite + FAISS"
굳이 무거운 PostgreSQL로 안 갈아타도 됩니다.

1.  **저장**: 벡터 데이터는 그냥 `SQLite`에 `BinaryField`나 `JSONField`로 저장합니다. (단순 보관용)
2.  **검색**: 검색할 때만 **`FAISS`** (페이스북이 만든 라이브러리)를 씁니다.
    -   서버 켜질 때: SQLite에서 벡터 꺼내서 FAISS 메모리에 올림.
    -   검색 요청: FAISS에서 순식간에 찾음.
    -   결과 반환: 찾은 ID로 SQLite에서 영화 정보 조회.

### 결론
-   **DB 바꿀 필요 없음**: 현재 코드 그대로 유지 가능.
-   **추가할 것**: `pip install faiss-cpu` 하나면 끝.
-   **포트폴리오**: "SQLite의 한계를 FAISS로 극복해서 하이브리드로 구성했다"고 하면 더 멋진 스토리가 됩니다.

## 10. Q&A: "무슨 기능을 만들 수 있지? 벡터 디비로는?"

**"비슷한 거 찾기"**가 핵심입니다. 이걸 응용하면 이런 기능들이 나옵니다.

### 1. "이 영화와 비슷한 영화" (Similar Movies)
-   **기능**: 상세 페이지 하단에 "이 영화를 본 사람이 좋아할 만한 영화" 리스트업.
-   **구현**: 현재 보고 있는 영화의 벡터와 가장 가까운 5개를 FAISS로 찾음.

### 2. "느낌으로 검색" (Semantic Search)
-   **기능**: "우울할 때 보기 좋은 영화"라고 검색하면 슬픈 영화 추천.
-   **구현**: 검색어("우울할 때...")를 벡터로 바꾸고, 영화 벡터들과 비교.

### 3. "실시간 개인화" (Real-time Personalization)
-   **기능**: 유저가 방금 클릭한 영화들의 평균 벡터를 구해서, 메인 화면을 즉시 바꿈.
-   **구현**: (클릭1 + 클릭2 + 클릭3) / 3 = **현재 유저 취향**. 이걸로 FAISS 검색.

**한 줄 요약**: "키워드가 안 겹쳐도, **느낌(Vector)**이 비슷한 걸 찾아주는 모든 기능"을 만들 수 있습니다.

1.  **지금 당장**: 굳이 안 써도 됩니다. (메모리에 모델 띄워서 계산해도 충분)
2.  **욕심이 난다면**: `pgvector`를 도입해서 "대용량 트래픽 대비도 해봤다"고 어필하세요.
