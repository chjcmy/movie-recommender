# PyTorch의 벡터 연산 원리 (Under the Hood)

질문하신 **"PyTorch가 어떻게 벡터 연산을 하는가?"**에 대한 심층 설명입니다.
코드의 핵심 라인인 `return (u * i).sum(1)`이 내부적으로 어떻게 작동하는지 시각적으로 풀어보겠습니다.

## 1. 데이터의 형태 (Shape)
먼저 데이터가 어떤 모양으로 들어오는지 상상해야 합니다.
`batch_size=3` (한 번에 3개의 데이터를 처리)이고, `embed_dim=4` (특성이 4개)라고 가정해 봅시다.

```python
# u (Users): 3명의 유저, 각각 4개의 특성
u = torch.tensor([
    [0.1, 0.2, 0.3, 0.4],  # 유저 1
    [0.5, 0.6, 0.7, 0.8],  # 유저 2
    [0.9, 0.1, 0.2, 0.3]   # 유저 3
])
# Shape: (3, 4)

# i (Items): 3개의 영화, 각각 4개의 특성
i = torch.tensor([
    [1.0, 2.0, 1.0, 2.0],  # 영화 A (유저 1이 본 영화)
    [0.5, 0.5, 0.5, 0.5],  # 영화 B (유저 2가 본 영화)
    [2.0, 2.0, 2.0, 2.0]   # 영화 C (유저 3이 본 영화)
])
# Shape: (3, 4)
```

## 2. 요소별 곱셈 (Element-wise Multiplication)
코드의 `u * i` 부분입니다.
PyTorch는 **같은 위치에 있는 숫자끼리** 곱합니다. 행렬 곱셈(Matrix Multiplication)이 아닙니다!

```python
multiplied = u * i
```

**계산 과정:**
- **유저 1 & 영화 A**: `[0.1*1.0, 0.2*2.0, 0.3*1.0, 0.4*2.0]` → `[0.1, 0.4, 0.3, 0.8]`
- **유저 2 & 영화 B**: `[0.5*0.5, 0.6*0.5, 0.7*0.5, 0.8*0.5]` → `[0.25, 0.30, 0.35, 0.40]`
- **유저 3 & 영화 C**: `[0.9*2.0, 0.1*2.0, 0.2*2.0, 0.3*2.0]` → `[1.8, 0.2, 0.4, 0.6]`

결과 `multiplied`의 Shape은 여전히 `(3, 4)`입니다.

## 3. 차원 축소 합계 (Summation over Dimension)
코드의 `.sum(1)` 부분입니다.
`dim=1`은 **가로 방향(열 방향)**으로 더하라는 뜻입니다. 즉, 각 유저-영화 쌍의 4개 특성 값을 모두 합쳐서 하나의 점수로 만듭니다.

```python
prediction = multiplied.sum(1)
```

**계산 과정:**
- **유저 1**: `0.1 + 0.4 + 0.3 + 0.8` = **1.6점**
- **유저 2**: `0.25 + 0.30 + 0.35 + 0.40` = **1.3점**
- **유저 3**: `1.8 + 0.2 + 0.4 + 0.6` = **3.0점**

결과 `prediction`의 Shape은 `(3,)`이 됩니다. (3개의 예측값)

## 4. PyTorch의 마법: 병렬 처리 (Parallelization)
"그냥 for문 돌려서 곱하고 더하면 되는 거 아니야?"라고 생각할 수 있습니다.
하지만 PyTorch는 이 연산을 **C++과 CUDA(GPU)** 레벨에서 수행합니다.

1.  **SIMD (Single Instruction, Multiple Data)**: CPU에서도 한 번의 명령어로 여러 숫자를 동시에 곱합니다.
2.  **GPU 가속**: GPU는 수천 개의 코어를 가지고 있어서, 위에서 본 3명의 유저뿐만 아니라 1024명(Batch Size)의 데이터를 **동시에** 계산해버립니다.

## 5. 자동 미분 (Autograd)
이게 제일 중요합니다. PyTorch는 우리가 `*`와 `sum`을 할 때, **"누가 누구랑 곱해졌는지"를 몰래 기록(Computational Graph)**해둡니다.

- 나중에 `loss.backward()`를 호출하면, 이 기록을 거꾸로 따라가면서
- *"아, 결과값이 1.6이 나왔는데 실제는 5.0이네? 3.4만큼 부족하네?"*
- *"그럼 아까 곱했던 0.1(유저 특성)을 좀 키워야겠다!"*
라고 판단하여 미분값(Gradient)을 자동으로 계산해줍니다.

---

## 요약
1.  **`u * i`**: 같은 위치끼리 곱한다 (특성별 매칭).
2.  **`.sum(1)`**: 가로로 다 더해서 하나의 점수로 만든다.
3.  **속도**: C++/CUDA로 최적화되어 엄청 빠르다.
4.  **학습**: 연산 과정을 기억해뒀다가 자동으로 미분해준다.
