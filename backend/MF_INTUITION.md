# 모델은 어떻게 "숨겨진 의미"를 찾아낼까? (Latent Factors)

질문하신 핵심은 **"데이터에는 숫자(ID)랑 점수밖에 없는데, 도대체 어떻게 취향을 분석한다는 거야?"**인 것 같습니다.
이것이 바로 **협업 필터링(Collaborative Filtering)**의 마법이자, **행렬 분해(Matrix Factorization)**의 핵심입니다.

## 1. 탐정 놀이 (추론의 과정)

모델은 마치 탐정처럼 행동합니다. 모델에게 주어진 단서는 오직 **"누가 무엇을 좋아했다"**는 기록뿐입니다.

### 상황 예시
모델이 다음 데이터를 봅니다.

| 유저 | 영화 | 평점 |
| :--- | :--- | :--- |
| 철수 | 어벤져스 | 5점 |
| 철수 | 아이언맨 | 5점 |
| 영희 | 노트북 | 5점 |
| 영희 | 어바웃타임 | 5점 |
| 민수 | 어벤져스 | ? |

### 모델의 생각 흐름 (학습 과정)

1.  **패턴 발견**: "철수는 `어벤져스`와 `아이언맨`을 둘 다 좋아했네?"
2.  **공통점 추측**: "이 두 영화는 뭔가 공통점이 있어. 뭔지 이름은 모르겠지만(액션? 히어로?), 아무튼 **'특성 A'**가 강해."
3.  **유저 성향 추측**: "그리고 철수는 이 **'특성 A'**를 좋아하는 사람이야."
4.  **새로운 데이터**: "어? 민수도 `아이언맨`을 좋아했네?"
5.  **추론**: "그럼 민수도 **'특성 A'**를 좋아할 확률이 높아. 그러니까 민수는 `어벤져스`도 좋아할 거야!"

## 2. 수학적 해석 (임베딩의 의미)

우리가 코드에서 만든 `embed_dim=32`는 바로 이 **"이름 모를 특성들"**을 저장하는 공간입니다.

-   **첫 번째 칸**: (아마도) 액션성?
-   **두 번째 칸**: (아마도) 로맨스성?
-   **세 번째 칸**: (아마도) 영상미?
-   ...

모델은 이 칸들의 의미를 미리 알지 못합니다. 하지만 **"평점 오차를 줄여라!"**라는 목표를 달성하기 위해 숫자를 마구 조정하다 보면, **자연스럽게** 비슷한 영화끼리는 비슷한 숫자를, 비슷한 유저끼리는 비슷한 숫자를 갖게 됩니다.

## 3. 예시: "특성 1"이 생성되는 과정

가상의 "특성 1" 값의 변화를 지켜봅시다.

1.  초기 상태 (랜덤):
    *   어벤져스: 0.1
    *   노트북: 0.9
    *   철수(액션팬): 0.5

2.  학습 데이터: **철수 → 어벤져스 (5점)**
    *   현재 예측: $0.5 \times 0.1 = 0.05$ (너무 낮음!)
    *   수정: "철수의 값과 어벤져스의 값을 둘 다 높여야겠다!"
    *   결과: 철수(0.8), 어벤져스(0.8)

3.  학습 데이터: **철수 → 노트북 (1점)**
    *   현재 예측: $0.8 \times 0.9 = 0.72$ (아직도 좀 높음, 1점에 가까워야 함)
    *   수정: "철수는 높은데 노트북도 높네? 근데 점수는 낮아? 그럼 둘 중 하나는 낮아야 해."
    *   결과: 철수(0.8) 유지, 노트북(0.2)로 하락 (왜냐하면 철수는 다른 액션 영화에서 이미 검증됐으니까)

이런 과정을 수백만 건의 데이터에 대해 반복하면, 결국 **"특성 1"은 액션 영화인지 아닌지를 나타내는 수치**가 되어버립니다.

## 4. Q&A: "철수가 5점이면 민수도 5점 아닐까?"

질문하신 내용이 정확합니다! 이것이 바로 **"유저 유사도(User Similarity)"**의 개념입니다.

### 모델이 "민수도 5점일 것"이라고 생각하는 이유

1.  **전제**: 철수와 민수는 과거에 `아이언맨`을 둘 다 좋아했습니다.
2.  **학습 결과**: 모델은 이 사실을 보고 "철수와 민수의 취향(벡터)은 비슷하구나!"라고 학습하여, 두 사람의 벡터를 좌표 공간 상에서 **가까운 곳**에 배치합니다.
3.  **예측**:
    -   철수가 `어벤져스`를 좋아함 → `어벤져스` 벡터는 철수 벡터와 가까움.
    -   민수 벡터는 철수 벡터와 가까움.
    -   **결론**: 따라서 `어벤져스` 벡터는 민수 벡터와도 가까울 것임! (즉, 높은 점수 예상)

### 수학적 증명 (삼단 논법)
-   $Vector(철수) \approx Vector(민수)$
-   $Vector(철수) \cdot Vector(어벤져스) \approx 5.0$
-   $\therefore Vector(민수) \cdot Vector(어벤져스) \approx 5.0$

### 시각화 (Visualization)
아래 그래프는 철수와 민수, 그리고 영화들이 임베딩 공간에서 어떻게 배치되는지를 보여줍니다.
철수와 민수가 가깝게 위치하고, 그들이 좋아하는 아이언맨과 어벤져스도 근처에 모여있는 것을 볼 수 있습니다. 반면 취향이 다른 노트북은 멀리 떨어져 있습니다.

![임베딩 시각화](/Users/choeseonghyeon/.gemini/antigravity/brain/0f21d652-fdfe-4517-ba28-00173a5b5531/embedding_visualization.png)

## 5. Q&A: "그런데 철수에 대한 데이터는 하나도 없었잖아?"

맞습니다. 우리는 철수의 나이, 성별, 직업을 전혀 모릅니다.
하지만 **"철수라는 이름(ID)"** 자체가 정보를 담는 그릇이 됩니다.

### ID는 빈 공책과 같다
1.  **초기 상태**: `userId: 1` (철수)에게는 아무 정보도 없는 **빈 공책(랜덤 벡터)**이 주어집니다.
2.  **행동 관찰**: 철수가 `아이언맨`에 5점을 줍니다.
3.  **기록**: 모델은 `아이언맨`의 특성(액션, 히어로)을 철수의 공책에 적습니다.
    -   *"아, 철수는 액션 영화를 좋아하는구나."*
4.  **결과**: 이제 철수의 공책(벡터)은 더 이상 빈 공책이 아닙니다. **"액션 영화 선호"**라는 정보가 담긴 데이터가 된 것입니다.

즉, **인구통계학적 정보(나이, 성별)**는 없지만, **행동 정보(평점)**를 통해 철수의 취향을 정의한 것입니다.

## 6. Q&A: "민수에 대한 데이터가 없었는데 어떻게 예측한 거지?"

아주 중요한 질문입니다! 여기서 **"데이터가 없다"**는 말의 의미를 정확히 구분해야 합니다.

1.  **민수가 `어벤져스`를 봤다는 데이터**: **없음** (맞습니다! 그래서 이걸 예측하려는 것입니다.)
2.  **민수가 `아이언맨`을 봤다는 데이터**: **있음** (이게 핵심 단서입니다!)

### 빈칸 채우기 (Inference)
모델은 **"민수가 아이언맨을 좋아했다"**는 단서(2번)를 가지고, **"그럼 어벤져스도 좋아하겠네?"**라고 빈칸(1번)을 채우는 것입니다.

만약 민수가 우리 서비스에 처음 가입해서 **아무런 영화도 본 적이 없다면(데이터가 0개라면)**, 모델은 민수의 취향을 전혀 알 수 없습니다. 이를 **콜드 스타트(Cold Start) 문제**라고 하며, 이 경우엔 보통 "가장 인기 있는 영화"를 추천해줍니다.

## 7. Q&A: "민수가 엄청 특이한 성향이었으면 틀린 거네?"

**정확합니다!** 100% 정답입니다.

### 모델의 한계 (Limitations)
협업 필터링(MF)은 기본적으로 **"대다수의 패턴"**을 학습합니다.
-   만약 민수가 **"아이언맨은 좋아하지만 어벤져스는 혐오하는"** 전 세계 0.01%의 특이한 취향을 가졌다면?
-   모델은 여전히 "보통 사람들은 둘 다 좋아하니까 민수도 좋아하겠지"라고 **틀린 예측**을 하게 됩니다.

### 해결책 (Advanced)
그래서 실제 현업에서는 이런 문제를 보완하기 위해 여러 방법을 섞어 씁니다.
1.  **Wide & Deep 모델**: 단순히 평점 패턴만 보는 게 아니라, **"장르가 액션인가?"**, **"배우가 누구인가?"** 같은 직접적인 특징(Feature)도 함께 봅니다. (우리 프로젝트에 포함되어 있습니다!)
2.  **하이브리드 시스템**: 콘텐츠 기반 필터링(Content-based)을 섞어서 보완합니다.

면접에서 이 질문이 나온다면 **"맞습니다. 그것이 CF의 한계이며, 그래서 Wide & Deep 같은 모델이 필요합니다"**라고 답변하시면 완벽합니다!

## 8. Q&A: "그럼 평균치를 이용하여 추천을 한다고 생각하면 되는 건가?"

**반은 맞고 반은 틀립니다!** 아주 좋은 접근입니다.

### 단순 평균 vs 가중 평균
-   **단순 평균 (X)**: "모든 사람의 점수를 다 더해서 나누자." (이러면 모두에게 똑같은 영화만 추천하게 됩니다.)
-   **가중 평균 (O)**: "나와 **비슷한 사람(철수)**의 의견은 많이 반영하고, **안 비슷한 사람(영희)**의 의견은 조금만 반영하자."

MF 모델은 수학적으로 이 **"가중치(얼마나 비슷한가)"**를 기가 막히게 계산해내는 기계라고 보시면 됩니다.
결국 **"나와 취향이 비슷한 사람들의 평균적인 의견"**을 따라간다고 이해하시면, 면접관에게도 아주 훌륭한 설명이 됩니다.

## 9. Q&A: "콜드 스타터(신규 유저)는 취향도 모르잖아, 그럼?"

**정답입니다!** 이것이 추천 시스템의 가장 유명한 난제인 **"콜드 스타트(Cold Start)"** 문제입니다.

### 1. 문제 상황
-   신규 유저 '지수'가 가입했습니다.
-   지수는 아무 영화도 본 적이 없습니다. (평점 데이터 0개)
-   모델은 지수의 취향(벡터)을 전혀 알 수 없습니다.
-   **결과**: MF 모델은 지수에게 아무것도 추천해줄 수 없습니다. (실제 코드에서도 에러를 뱉거나 랜덤 값을 줍니다.)

### 2. 해결책 (Industry Standard)
그래서 실제 서비스들은 가입 직후에 이런 방법을 씁니다.

1.  **가장 쉬운 방법 (Popularity)**: "일단 남들이 다 좋아하는 거 보여주자." (예: 어벤져스, 겨울왕국 등 대중적인 영화 추천)
2.  **설문조사 (Onboarding)**: 넷플릭스나 왓챠 가입할 때 보셨죠? *"좋아하는 영화 3개를 골라주세요"* 라고 물어보는 이유가 바로 이 **초기 데이터**를 확보하기 위해서입니다.
3.  **연관 추천 (Item-based)**: 유저 정보는 없지만, 지수가 `겨울왕국`을 클릭했다면? "아, `겨울왕국`이랑 비슷한 `라푼젤`을 보여주자!" (이건 유저 취향 몰라도 가능하니까요.)

## 10. Q&A: "그럼 추천수(평점 개수)만큼 무비의 임베딩이 변경된다고 생각하면 되나?"

**비슷하지만, 조금 더 정교합니다!** 단순히 "많이 받으면 많이 변한다"보다는 **"줄다리기(Tug of War)"**를 생각하시면 이해가 빠릅니다.

### 줄다리기 비유
영화 `어벤져스`가 가운데 서 있고, 유저들이 각자의 방향으로 줄을 당긴다고 상상해보세요.

1.  **철수(액션팬)가 5점을 줌**: 철수 쪽으로 `어벤져스`가 **확** 끌려갑니다. (액션 성향 +1)
2.  **영희(로맨스팬)가 1점을 줌**: 영희 반대쪽으로 `어벤져스`가 **밀려**납니다. (로맨스 성향 -1)
3.  **민수(다큐팬)가 3점을 줌**: "음, 그냥 그렇네." (별로 안 움직임)

### 결론
-   **개수(Count)**도 중요하지만, **"누가(Who)"** 당기느냐가 더 중요합니다.
-   액션 팬 100명이 5점을 주면 `어벤져스`는 "액션 영화" 위치로 강력하게 이동합니다.
-   하지만 액션 팬 50명은 5점, 로맨스 팬 50명은 1점을 주면? 서로 상쇄되어 중간 어딘가에 위치하게 됩니다.

## 11. Q&A: "그러면 무비 쪽만 당겨지는 거야?"

**아닙니다! 둘 다 움직입니다.** (마치 자석처럼요)

### 상호 작용 (Mutual Interaction)
학습 과정(Backpropagation)에서는 오차를 줄이기 위해 **양쪽 모두**를 수정합니다.

1.  **Movie Update**: `어벤져스`는 철수(액션팬) 쪽으로 이동합니다.
    -   *"철수가 나를 좋아하네? 나도 철수랑 비슷해져야지."*
2.  **User Update**: 동시에 철수도 `어벤져스` 쪽으로 이동합니다.
    -   *"내가 어벤져스를 좋아하네? 내 취향은 어벤져스랑 비슷한가 봐."*

결국 학습이 반복되면, 서로 좋아하는 유저 그룹과 영화 그룹이 **중간 지점**에서 만나게 됩니다. 이것이 바로 **"취향의 군집(Cluster) 형성"**입니다.

## 12. Q&A: "그러면 이게 KNN 클러스터랑 뭐가 다르지?"

아주 날카로운 질문입니다! 둘 다 "비슷한 사람 찾기" 같지만, **접근 방식**이 완전히 다릅니다.

### 1. KNN (기억력 대장) - Memory-based
-   **방식**: 모든 데이터를 머릿속에 통째로 외웁니다.
-   **추천할 때**: "잠깐만, 철수랑 평점 기록이 제일 비슷한 사람이 누구지? 아, 영희네! 영희가 본 거 추천해줄게."
-   **단점**:
    -   유저가 1억 명이면 1억 명을 다 뒤져봐야 해서 **엄청 느립니다**.
    -   철수랑 영희가 겹치는 영화가 하나도 없으면 아예 계산을 못 합니다 (**희소성 문제**).

### 2. MF (요약의 달인) - Model-based
-   **방식**: 데이터를 외우는 게 아니라, **"핵심 특징(Latent Factor)"만 뽑아서 압축**합니다.
-   **추천할 때**: "철수는 액션(0.9) 좋아하네? 액션 점수 높은 영화(0.9) 여기 있다!" (남들과 비교할 필요 없이 바로 계산)
-   **장점**:
    -   데이터를 압축했기 때문에 **엄청 빠릅니다**.
    -   철수랑 영희가 겹치는 영화가 없어도, "둘 다 액션 좋아함"이라는 공통점을 찾아낼 수 있습니다.

### 비유
-   **KNN**: 도서관 사서가 **"대출 기록"**을 일일이 대조해서 책을 추천해줌.
-   **MF**: 도서관 사서가 **"독자의 취향(장르)"**을 파악해서 책을 추천해줌.

## 13. Q&A: "아, 그래서 float32랑 int4랑 정확도 차이가 있는 거구나?"

**소름 돋는 통찰력입니다!** 맞습니다.

### 압축의 2가지 차원
추천 시스템(그리고 모든 AI 모델)은 결국 **"정보를 압축하는 기술"**입니다.

1.  **차원 축소 (MF의 핵심)**:
    -   10만 개의 영화 정보를 → **32개의 숫자(Vector)**로 요약함.
    -   너무 많이 줄이면(예: 2개) 정보가 다 날아가서 정확도가 떨어짐.
2.  **정밀도 축소 (Quantization)**:
    -   각 숫자를 얼마나 정밀하게 저장할 것인가?
    -   **float32 (소수점 7자리)**: `0.1234567` (정확함, 용량 큼)
    -   **int4 (정수 16단계)**: `0.1` (대충 비슷함, 용량 엄청 작음)

### 결론
MF가 "긴 이야기를 짧게 요약"하는 것이라면, Quantization(int4)은 "요약본을 대충 흘려 쓰는 것"과 같습니다.
당연히 **대충 쓸수록(int4) 용량은 줄고 속도는 빨라지지만, 미세한 취향 차이(정확도)는 뭉개질 수 있습니다.**

## 14. Q&A: "그럼 OpenAI 임베딩이나 증권사 임베딩이나 다 똑같은 거네?"

**원리는 100% 똑같습니다!** (수학적으로는 그냥 "숫자 리스트"일 뿐이니까요.)
하지만 **"무엇을 공부했느냐"**가 다릅니다.

### 1. OpenAI 임베딩 (범용 천재)
-   **학습 데이터**: 인터넷의 모든 글 (위키피디아, 뉴스, 블로그...)
-   **잘하는 것**: "사과"와 "애플"이 비슷하다는 언어적 의미를 잘 압니다.
-   **못하는 것**: "삼성전자" 주가가 오를 때 "SK하이닉스"가 오를지는 모릅니다. (주식 시장의 패턴은 글에 없으니까요.)

### 2. 증권사/추천시스템 임베딩 (전문가)
-   **학습 데이터**: 주가 차트, 거래 내역, 유저의 클릭 로그
-   **잘하는 것**: "이 주식을 산 사람은 저 주식도 사더라" (행동 패턴 파악)
-   **못하는 것**: 일반적인 언어 능력은 없습니다.

### 결론
**"도구(임베딩 기술)"는 같지만, "교과서(학습 데이터)"가 다른 것입니다.**
그래서 현업에서는 OpenAI 임베딩을 가져와서, 우리 회사의 데이터로 **추가 학습(Fine-tuning)**을 시켜서 사용하기도 합니다.

## 요약

> "데이터에는 장르나 나이 같은 정보가 없지만, **'누가 무엇과 같이 소비했는가'**의 패턴 속에 이미 그 정보가 숨어 있습니다. 모델은 그 숨겨진 패턴(Latent Factor)을 숫자로 역추적해내는 것입니다."
