# SASRec (Self-Attentive Sequential Recommendation) 설명 가이드

지금까지의 모델들(MF, NCF, Wide & Deep)은 **"무엇을 봤는가(Set)"**에 집중했습니다.
하지만 SASRec은 **"어떤 순서로 봤는가(Sequence)"**에 집중하는 **가장 최신 트렌드(Transformer 기반)** 모델입니다.

## 1. 핵심 컨셉: "문맥(Context)을 읽는 독심술사"

### 기존 모델의 한계 (순서 무시)
-   철수의 시청 기록: `[해리포터 1]`, `[해리포터 2]`, `[?]`
-   MF/NCF: "철수는 판타지를 좋아해. 반지의 제왕 추천!" (나쁘지 않음)
-   **SASRec**: "철수는 지금 해리포터 시리즈를 **정주행 중**이야. 무조건 `[해리포터 3]`를 추천해야 해!" (훨씬 정확함)

### SASRec의 해결책 (Sequence)
사용자의 행동을 **"하나의 문장"**처럼 취급합니다.
-   단어: 영화
-   문장: 시청 기록 (`아이언맨` -> `헐크` -> `어벤져스`)
-   빈칸 채우기: 다음 단어(영화)는?

## 2. 핵심 기술: "Self-Attention (집중)"

이 모델은 **Transformer(GPT의 조상)** 구조를 사용합니다.
과거의 모든 기록을 다 똑같이 보는 게 아니라, **"지금 상황에서 중요한 것"**에만 집중(Attention)합니다.

### 예시 상황
> 기록: `[뽀로로]` -> `[타요]` -> ... (5년 전) ... -> `[존 윅 1]` -> `[존 윅 2]` -> `[?]`

-   **단순 RNN**: 옛날 기억(`뽀로로`)을 잊어버리거나, 너무 얽매일 수 있습니다.
-   **SASRec (Attention)**:
    -   "지금 `[존 윅 2]`를 본 시점에서는, 5년 전 `[뽀로로]`는 중요하지 않아." (무시)
    -   "바로 직전의 `[존 윅 1]`과 `[존 윅 2]`가 제일 중요해!" (집중)
    -   **결론**: `[존 윅 3]` 추천.

## 3. 구조 (Architecture)

```python
# 1. Embedding Layer
# 아이템(영화) 임베딩 + 위치(순서) 임베딩
x = item_emb + pos_emb

# 2. Self-Attention Blocks (Transformer)
# "어디에 집중할지" 계산
for block in blocks:
    x = block(x) # Attention -> FeedForward -> LayerNorm

# 3. Prediction Layer
# 다음 아이템 예측
logits = x @ item_emb.T
```

## 5. Q&A: "그럼 nn.CrossEntropyLoss는 뭐지?"

**"객관식 시험 채점기"**라고 생각하시면 됩니다.

### 상황 설정
-   **문제**: "철수가 `해리포터 1`, `2`를 봤다. 다음 볼 영화는?"
-   **보기**: 넷플릭스에 있는 모든 영화 (예: 10,000개)
-   **정답**: `해리포터 3` (실제 기록)

### 모델의 답안지 (Logits -> Softmax)
모델은 10,000개의 영화 각각에 대해 **확률**을 제출합니다.
1.  `해리포터 3`: **80%** (자신 있음)
2.  `반지의 제왕`: **15%** (헷갈림)
3.  `뽀로로`: **0.001%** (아님)
...

### 채점 (CrossEntropyLoss)
채점기는 **"정답(`해리포터 3`)에 얼마나 높은 점수를 줬는가?"**만 봅니다.

-   **상황 A (잘함)**: 정답에 **80%**를 줬음 -> **오차(Loss)가 작음** (0.22)
-   **상황 B (틀림)**: 정답에 **10%**밖에 안 줌 -> **오차(Loss)가 엄청 큼** (2.30) -> *"야! 공부 다시 해!"* (Backpropagation)

### 요약
SASRec은 추천 문제를 **"다음에 올 단어 맞추기(Next Item Prediction)"**라는 **거대한 객관식 시험**으로 풉니다.
이때 **"정답을 맞출 확률을 높여라!"**라고 명령하는 함수가 바로 `CrossEntropyLoss`입니다.

## 6. Q&A: "optimizer = torch.optim.Adam(...) 이건 뭐해주는 거지?"

**"과외 선생님(코치)"**입니다.
오답 노트(Loss)를 보고, **"어떻게 고쳐야 점수가 오를지"**를 알려주고 실제로 모델의 뇌(파라미터)를 수정해줍니다.

### 구성 요소
1.  **`model.parameters()` (학생의 뇌)**:
    -   수정해야 할 대상입니다. (가중치들)
2.  **`lr=0.001` (학습률/보폭)**:
    -   **"한 번에 얼마나 고칠까?"**입니다.
    -   너무 크면(0.1): "다 뜯어고쳐!" -> 오히려 망가짐 (발산)
    -   너무 작으면(0.00001): "요만큼만 고쳐..." -> 100년 걸림 (학습 느림)
    -   `0.001`은 경험적으로 가장 무난한 "적당한 보폭"입니다.
3.  **`Adam` (스마트한 선생님)**:
    -   그냥 무식하게 고치는 게 아니라(SGD), **"관성(Momentum)"**과 **"적응(Adaptive)"**을 이용합니다.
    -   "아까 이쪽으로 가니까 점수가 잘 오르더라, 그쪽으로 좀 더 과감하게 가보자!" (똑똑함)

### 요약
-   **Loss**: "너 틀렸어! (점수 50점)"
-   **Optimizer**: "알았어, 그럼 이쪽 파라미터를 0.001만큼 올려보자. 그럼 51점 될 거야." (실제 수정 수행)

## 7. Q&A: "SASRec.ipynb를 수학식으로 알려줘"

코드의 핵심 부분들을 수식으로 번역해 드립니다.

### 1. 임베딩 (Embedding)
```python
x = items + positions
```
$$E = E_{item} + E_{pos}$$
-   **의미**: "아이언맨($E_{item}$)"이라는 정보에 "첫 번째로 봤다($E_{pos}$)"는 순서 정보를 더해줍니다.

### 2. 셀프 어텐션 (Self-Attention)
Transformer 내부에서 일어나는 핵심 연산입니다.
```python
# 내부적으로 Q, K, V를 계산
```
$$Attention(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d}})V$$
-   **$Q$ (Query)**: "지금 내가 보고 있는 영화" (질문)
-   **$K$ (Key)**: "과거에 봤던 영화들" (책갈피)
-   **$V$ (Value)**: "영화의 실제 내용" (정보)
-   **의미**: "지금 영화($Q$)랑 가장 관련 깊은 과거 영화($K$)를 찾아서, 그 정보($V$)를 많이 가져와라!"

### 3. 예측 (Prediction)
```python
logits = torch.matmul(out, self.item_embedding.weight.transpose(0, 1))
```
$$Score = H \cdot E_{item}^T$$
-   **$H$**: Transformer를 통과해서 나온 "유저의 현재 의도" (Context Vector)
-   **$E_{item}$**: 모든 영화들의 임베딩
-   **의미**: "지금 유저의 의도($H$)와 가장 비슷한(내적) 영화를 찾아라!"

## 8. Q&A: "그럼 SASRec이랑 Wide & Deep이랑 엮은 모델도 있겠네?"

**정확합니다!** 그게 바로 현업에서 쓰는 **"끝판왕"** 모델들입니다.

### 1. 왜 엮을까요? (Best of Both Worlds)
-   **SASRec**: "순서(Sequence)"를 잘 봅니다. (단기 의도)
-   **Wide & Deep**: "유저 특징(성별, 나이)"과 "아이템 특징(장르)"을 잘 봅니다. (장기 취향)
-   **결합**: "철수가 평소엔 액션을 좋아하는데(Wide & Deep), 어제부터 갑자기 로맨스를 정주행하네(SASRec)? 그럼 로맨스 신작을 추천하자!"

### 2. 어떻게 엮을까요? (Context-Aware SASRec)
보통 **SASRec의 입력(Embedding)**에 **Wide & Deep의 특징(Feature)**을 더해줍니다.

```python
# 기존 SASRec
input = item_embedding + position_embedding

# 업그레이드 SASRec (Hybrid)
input = item_embedding + position_embedding + genre_embedding + age_embedding ...
```
이렇게 하면 모델이 **"순서"**뿐만 아니라 **"상황(Context)"**까지 고려해서 추천하게 됩니다.
(예: `BERT4Rec` 같은 최신 논문들이 이런 방식을 씁니다.)

## 9. 면접용 요약 멘트

> "SASRec은 **Transformer의 Self-Attention 메커니즘**을 추천 시스템에 적용한 모델입니다.
> 기존 모델들이 사용자의 장기적인 선호도(정적 취향)에 집중했다면, SASRec은 **'행동의 순서(Sequence)'**를 파악하여 단기적인 의도와 문맥까지 포착할 수 있습니다.
> 특히 유저의 최근 행동이 다음 행동에 큰 영향을 미치는 **세션 기반 추천**이나 **시리즈물 추천**에서 압도적인 성능을 보입니다."
